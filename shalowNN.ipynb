{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, Y, num_iterations = 2000, learning_rate= 0.05, print_cost=False):\n",
    "    \n",
    "    #Define the structure\n",
    "    n_x, n_h, n_y = defineNNStructure(X, Y)\n",
    "    \n",
    "    #Initialize weights\n",
    "    parameters = initialize_randomly(n_x, n_h, n_y)\n",
    "    \n",
    "    #Run the model\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        #Forward Propagation\n",
    "        A2, cache = forwardPropagation(X, parameters)\n",
    "        \n",
    "        #computeCost\n",
    "        cost = computeCost(Y, A2)\n",
    "        if print_cost and i%100==0:\n",
    "            print(\"Cost at iteration \" + str(i) + \" is \" + str(cost))\n",
    "        \n",
    "        #Back Propagation\n",
    "        grads = backPropagation(X, Y, cache, parameters)\n",
    "        \n",
    "        #Update Parameters\n",
    "        parameters[\"W1\"] = parameters[\"W1\"] - learning_rate * grads[\"dW1\"]\n",
    "        parameters[\"b1\"] = parameters[\"b1\"] - learning_rate * grads[\"db1\"]\n",
    "        parameters[\"W2\"] = parameters[\"W2\"] - learning_rate * grads[\"dW2\"]\n",
    "        parameters[\"b2\"] = parameters[\"b2\"] - learning_rate * grads[\"db2\"]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 is [[-0.69311252]]\n",
      "Cost at iteration 100 is [[-0.6927492]]\n",
      "Cost at iteration 200 is [[-0.69079473]]\n",
      "Cost at iteration 300 is [[-0.68537457]]\n",
      "Cost at iteration 400 is [[-0.67972387]]\n",
      "Cost at iteration 500 is [[-0.67433599]]\n",
      "Cost at iteration 600 is [[-0.66658313]]\n",
      "Cost at iteration 700 is [[-0.65472318]]\n",
      "Cost at iteration 800 is [[-0.64225499]]\n",
      "Cost at iteration 900 is [[-0.63207209]]\n",
      "Cost at iteration 1000 is [[-0.62449957]]\n",
      "Cost at iteration 1100 is [[-0.61885491]]\n",
      "Cost at iteration 1200 is [[-0.61402198]]\n",
      "Cost at iteration 1300 is [[-0.60765436]]\n",
      "Cost at iteration 1400 is [[-0.59307222]]\n",
      "Cost at iteration 1500 is [[-0.56238017]]\n",
      "Cost at iteration 1600 is [[-0.52360082]]\n",
      "Cost at iteration 1700 is [[-0.48822628]]\n",
      "Cost at iteration 1800 is [[-0.45956649]]\n",
      "Cost at iteration 1900 is [[-0.43709367]]\n"
     ]
    }
   ],
   "source": [
    "#Run the model\n",
    "final_parameters = model(X, Y, 2000, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "#Find Accuracy\n",
    "def predict(X, parameters):\n",
    "    A2 = forwardPropagation(X, parameters)[0]\n",
    "    predictions = np.where(A2 > 0.5, 1, 0)\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(X, final_parameters)\n",
    "print(\"Accuracy: %d\" %float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defineNNStructure(X, Y):\n",
    "    n_x = X.shape[0]\n",
    "    n_h = 4\n",
    "    n_y = Y.shape[0]\n",
    "    return n_x, n_h, n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_randomly(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b1 = np.zeros((n_h, 1), dtype=float)\n",
    "    b2 = np.zeros((n_y, 1), dtype=float)\n",
    "    parameters = {\n",
    "        \"W1\" : W1,\n",
    "        \"b1\" : b1,\n",
    "        \"W2\" : W2,\n",
    "        \"b2\" : b2\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardPropagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {\n",
    "        \"Z1\" : Z1,\n",
    "        \"A1\" : A1,\n",
    "        \"Z2\" : Z2,\n",
    "        \"A2\" : A2\n",
    "    }\n",
    "    return A2, cache\n",
    "\n",
    "\n",
    "def tanh(Z):\n",
    "    H = (np.exp(Z) - np.exp(-Z))/(np.exp(Z) + np.exp(-Z))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(Y, A2):\n",
    "    m = Y.shape[1]\n",
    "    cost = (1/m) * (np.dot(Y, np.log(A2.T)) + np.dot(1-Y, np.log(1 - A2.T)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backPropagation(X, Y, cache, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    Z1 = cache[\"Z1\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    Z2 = cache[\"Z2\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\n",
    "        \"dW2\" : dW2,\n",
    "        \"db2\" : db2,\n",
    "        \"dW1\" : dW1,\n",
    "        \"db1\" : db1\n",
    "    }\n",
    "    \n",
    "    return grads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
